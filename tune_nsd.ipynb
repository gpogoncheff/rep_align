{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import madry\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10, ImageFolder, ImageNet\n",
    "from torchvision.models import resnet50, alexnet\n",
    "from rep_align.models.model_factory import get_model\n",
    "from rep_align.utils.lr_scheduling import *\n",
    "from rep_align.data.nsd_data import NSDVoxels\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "WANDB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "def get_activations(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output\n",
    "    return hook\n",
    "\n",
    "def evaluate_clf(model, data, device='cuda'):\n",
    "    model.eval()\n",
    "    n, total_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for img, label in data:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(img)\n",
    "            n += len(label)\n",
    "            total_correct += torch.sum(torch.argmax(output, dim=-1) == label).item()\n",
    "    return total_correct/n\n",
    "\n",
    "def evaluate(student_model, teacher_model, data, loss_fn_predict, \n",
    "             loss_fn_kd, alpha_kd, epoch, device='cuda'):\n",
    "    student_model.eval()\n",
    "    n, running_total_loss, running_loss_prediction, running_loss_kd = 0, 0, 0, 0\n",
    "    with tqdm(data, unit='batch') as epoch_progress:\n",
    "        epoch_progress.set_description(f'eval {epoch}')\n",
    "        with torch.no_grad():\n",
    "            for img, target in epoch_progress:\n",
    "                img = img.to(device)\n",
    "                target = target.to(device)\n",
    "                output_student = student_model(img)\n",
    "                output_teacher = teacher_model(img)\n",
    "                loss_predict = get_predict_loss(student_model, activations['student_feats'], target, loss_fn_predict)\n",
    "                loss_kd = get_kd_loss(output_student, output_teacher, loss_fn_kd)\n",
    "                total_loss = loss_predict + alpha_kd*loss_kd\n",
    "\n",
    "                n += len(target)\n",
    "                running_loss_prediction += loss_predict.item()*len(target)\n",
    "                running_loss_kd += loss_kd.item()*len(target)\n",
    "                running_total_loss += total_loss.item()*len(target)\n",
    "                epoch_progress.set_postfix(\n",
    "                    predict_loss='{:.4f}'.format((running_loss_prediction/n)), \n",
    "                    kd_loss='{:.4f}'.format((running_loss_kd/n)), \n",
    "                    total_loss='{:.4f}'.format((running_total_loss/n))\n",
    "                )\n",
    "\n",
    "    prediction_loss = running_loss_prediction/n\n",
    "    kd_loss = running_loss_kd/n\n",
    "    total_loss = running_total_loss/n\n",
    "    if WANDB:\n",
    "        wandb.log(\n",
    "            {'val_prediction_loss': prediction_loss,\n",
    "             'val_kd_loss': kd_loss,\n",
    "             'val_total_loss': total_loss, \n",
    "             'epoch': epoch}\n",
    "        )\n",
    "    return prediction_loss, kd_loss, total_loss\n",
    "\n",
    "def get_predict_loss(student_model, student_feats, target, loss_fn_predict):\n",
    "    student_predictions = student_model.neural_predict(student_feats.flatten(1))\n",
    "    return loss_fn_predict(student_predictions, target)\n",
    "\n",
    "def get_kd_loss(student_out, teacher_out, loss_fn_kd):\n",
    "    student = F.log_softmax(student_out, dim=-1)\n",
    "    teacher = F.log_softmax(teacher_out, dim=-1)\n",
    "    return loss_fn_kd(student, teacher)\n",
    "\n",
    "def lwf_train_epoch(student_model, teacher_model, data, \n",
    "                    loss_fn_predict, loss_fn_kd, alpha_kd, \n",
    "                    optimizer, lr_scheduler, epoch, device='cuda'):\n",
    "    student_model.train()\n",
    "    n, running_total_loss, running_loss_prediction, running_loss_kd = 0, 0, 0, 0\n",
    "    with tqdm(data, unit='batch') as epoch_progress:\n",
    "        epoch_progress.set_description(f'train {epoch}')\n",
    "        for img, target in epoch_progress:\n",
    "            img = img.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output_student = student_model(img)\n",
    "            output_teacher = teacher_model(img)\n",
    "            loss_predict = get_predict_loss(student_model, activations['student_feats'], target, loss_fn_predict)\n",
    "            loss_kd = get_kd_loss(output_student, output_teacher, loss_fn_kd)\n",
    "            total_loss = loss_predict + alpha_kd*loss_kd\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            new_lr = lr_scheduler.get_lr()\n",
    "            for group in optimizer.param_groups:\n",
    "                group['lr'] = new_lr\n",
    "                if WANDB:\n",
    "                    wandb.log({'lr': new_lr, 'lr_step': lr_scheduler.current_step})\n",
    "\n",
    "            n += len(target)\n",
    "            running_loss_prediction += loss_predict.item()*len(target)\n",
    "            running_loss_kd += loss_kd.item()*len(target)\n",
    "            running_total_loss += total_loss.item()*len(target)\n",
    "            epoch_progress.set_postfix(\n",
    "                predict_loss='{:.4f}'.format((running_loss_prediction/n)), \n",
    "                kd_loss='{:.4f}'.format((running_loss_kd/n)), \n",
    "                total_loss='{:.4f}'.format((running_total_loss/n))\n",
    "            )\n",
    "\n",
    "    prediction_loss = running_loss_prediction/n\n",
    "    kd_loss = running_loss_kd/n\n",
    "    total_loss = running_total_loss/n\n",
    "    if WANDB:\n",
    "        wandb.log(\n",
    "            {'train_prediction_loss': prediction_loss,\n",
    "             'train_kd_loss': kd_loss,\n",
    "             'train_total_loss': total_loss, \n",
    "             'epoch': epoch}\n",
    "        )\n",
    "    return prediction_loss, kd_loss, total_loss\n",
    "\n",
    "def run(student_model, teacher_model, neural_train_data, neural_val_data, clf_data, loss_fn_prediction, loss_fn_kd, \n",
    "          alpha_kd, optimizer, lr_scheduler, n_epochs, out_path=None, device='cuda'):\n",
    "    if WANDB:\n",
    "        wandb.init(project='repalign')\n",
    "\n",
    "    hist = {'train': [], 'val': []}\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(n_epochs):\n",
    "        train_prediction_loss, train_kd_loss, train_total_loss = lwf_train_epoch(\n",
    "            student_model, teacher_model, neural_train_data, loss_fn_prediction, \n",
    "            loss_fn_kd, alpha_kd, optimizer, lr_scheduler, epoch, device=device\n",
    "        )\n",
    "        \n",
    "        val_prediction_loss, val_kd_loss, val_total_loss = evaluate(\n",
    "            student_model, teacher_model, neural_val_data, \n",
    "            loss_fn_prediction, loss_fn_kd, alpha_kd, epoch, device=device\n",
    "        )\n",
    "        \n",
    "        val_clf_acc = evaluate_clf(student_model, clf_data, device=device)\n",
    "\n",
    "        hist['train'].append([train_prediction_loss, train_kd_loss, train_total_loss])\n",
    "        hist['val'].append([val_prediction_loss, val_kd_loss, val_total_loss, val_clf_acc])\n",
    "\n",
    "        if val_total_loss < best_loss:\n",
    "            best_loss = val_total_loss\n",
    "            if out_path is not None:\n",
    "                model_ckpt_data = {\n",
    "                    'student_state_dict': student_model.state_dict(),\n",
    "                    'teacher_state_dict': teacher_model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'hist': hist,\n",
    "                    'wandb_run_name': None if not WANDB else wandb.run.name,\n",
    "                }\n",
    "                torch.save(model_ckpt_data, os.path.join(out_path, 'best_val_loss.pt'))\n",
    "        \n",
    "    if WANDB:\n",
    "        wandb.finish()\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_10_train_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.4914, 0.4822, 0.4465],\n",
    "        [0.2470, 0.2435, 0.2616]\n",
    "    )\n",
    "])\n",
    "\n",
    "cifar_10_val_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.4914, 0.4822, 0.4465],\n",
    "        [0.2470, 0.2435, 0.2616]\n",
    "    )\n",
    "])\n",
    "\n",
    "num_workers = 8\n",
    "batch_size = 128\n",
    "\n",
    "nsd_data_root_train = '/DATA/nsd_sample/train'\n",
    "nsd_data_root_val = '/DATA/nsd_sample/val'\n",
    "voxel_rois = ['V4']\n",
    "nsd_train_data = NSDVoxels(nsd_data_root_train, voxel_rois, transforms=cifar_10_train_transform)\n",
    "nsd_val_data = NSDVoxels(nsd_data_root_val, voxel_rois, transforms=cifar_10_val_transform)\n",
    "nsd_train_dataloader = DataLoader(nsd_train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "nsd_val_dataloader = DataLoader(nsd_val_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "n_voxels = nsd_train_data[0][1].shape[0]\n",
    "\n",
    "\n",
    "cifar10_val_data = CIFAR10('/DATA/cifar10', \n",
    "                           train=False, transform=cifar_10_val_transform, download=False)\n",
    "cifar10_val_dataloader = DataLoader(cifar10_val_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet18_cifar10'\n",
    "\n",
    "student_model = get_model(model_type, n_classes=10)\n",
    "teacher_model = get_model(model_type, n_classes=10)\n",
    "\n",
    "state_dict = torch.load('./model_ckpts/resnet18_cifar10_base/best_loss.pt')['state_dict']\n",
    "student_model.load_state_dict(state_dict)\n",
    "teacher_model.load_state_dict(state_dict)\n",
    "\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model.eval()\n",
    "\n",
    "student_model.neural_predict = nn.Linear(2048, n_voxels, bias=True)\n",
    "\n",
    "student_model.to(device)\n",
    "teacher_model.to(device)\n",
    "\n",
    "original_acc = evaluate_clf(teacher_model, cifar10_val_dataloader)\n",
    "print(f'Original Accuracy: {original_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = {\n",
    "    'lr_scheduling_spec': 'constant',\n",
    "    'lr_init': 1e-4,\n",
    "    'optimizer_spec': 'adam',\n",
    "    'optimizer_params': {'weight_decay': 0.01},\n",
    "    'alpha_kd': 1.0,\n",
    "    'n_epochs': 10,\n",
    "    'out_path': './tune_tmp'\n",
    "}\n",
    "\n",
    "if run_config['lr_scheduling_spec'] == 'constant':\n",
    "    lr_scheduler = ConstantLR(run_config['lr_init'])\n",
    "elif run_config['lr_scheduling_spec'] == 'linear_warmup_cosine_decay':\n",
    "    lr_scheduler = LinearWarmupCosineDecayLR(run_config['warmup_start_lr'], \n",
    "                                             run_config['base_lr'], \n",
    "                                             run_config['warmup_steps']*len(nsd_train_dataloader), \n",
    "                                             run_config['max_steps']*len(nsd_train_dataloader), \n",
    "                                             run_config['eta_min'])\n",
    "\n",
    "if run_config['optimizer_spec'] == 'sgd':\n",
    "    optimizer = torch.optim.SGD(student_model.parameters(), **run_config['optimizer_params'])\n",
    "elif run_config['optimizer_spec'] == 'adam':\n",
    "    optimizer = torch.optim.Adam(student_model.parameters(), **run_config['optimizer_params'])\n",
    "\n",
    "loss_fn_prediction = nn.MSELoss()\n",
    "loss_fn_kd = nn.KLDivLoss(reduction='batchmean', log_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_kd = run_config['alpha_kd']\n",
    "\n",
    "student_hook = student_model.layer4.register_forward_hook(get_activations('student_feats'))\n",
    "teacher_hook = teacher_model.layer4.register_forward_hook(get_activations('teacher_feats'))\n",
    "\n",
    "run_hist =  run(student_model, teacher_model, nsd_train_dataloader, nsd_val_dataloader, \n",
    "                cifar10_val_dataloader, loss_fn_prediction, loss_fn_kd, run_config['alpha_kd'], \n",
    "                optimizer, lr_scheduler, run_config['n_epochs'], out_path=run_config['out_path'], device=device)\n",
    "\n",
    "student_hook.remove()\n",
    "teacher_hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rep_align.eval.interp_index import evaluate_interp_index\n",
    "\n",
    "ii_results_student = evaluate_interp_index(student_model, 'layer4', train_data=None, val_data=cifar10_val_data, device=device)\n",
    "ii_results_teacher = evaluate_interp_index(teacher_model, 'layer4', train_data=None, val_data=cifar10_val_data, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aligninterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
